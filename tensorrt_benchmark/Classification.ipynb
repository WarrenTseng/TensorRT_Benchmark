{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c21ee1c",
   "metadata": {},
   "source": [
    "## Create a model and export it as ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec55758",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "batch_size = 1\n",
    "device = 'cuda'\n",
    "model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254a8acd",
   "metadata": {},
   "source": [
    "After training..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40584a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './models/cls.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63037c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.randn(batch_size, 3, 256, 256).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(model(dummy_input).shape)\n",
    "\n",
    "torch.onnx.export(model, dummy_input, './models/cls.onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26755c2",
   "metadata": {},
   "source": [
    "## Convert the Torch model to Torch-TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d3e329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restart the notebook kernel\n",
    "import os\n",
    "os._exit(00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efea3267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_tensorrt\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import torch\n",
    "\n",
    "batch_size = 32\n",
    "device = 'cuda'\n",
    "model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2).to(device)\n",
    "model.load_state_dict(torch.load('./models/cls.pt'))\n",
    "\n",
    "# inputs = [torch_tensorrt.Input((32, 3, 256, 256))]\n",
    "# inputs = [torch_tensorrt.Input((64, 3, 256, 256))]\n",
    "\n",
    "inputs = [\n",
    "    torch_tensorrt.Input(\n",
    "        min_shape=[1, 3, 256, 256],\n",
    "        opt_shape=[32, 3, 256, 256],\n",
    "        max_shape=[256, 3, 256, 256],\n",
    "        dtype=torch.half,\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f885dde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "trt_model = torch_tensorrt.compile(model,\n",
    "                                   inputs=inputs,\n",
    "                                   enabled_precisions={torch_tensorrt.dtype.half})\n",
    "torch.jit.save(trt_model, 'models/cls_torchtrt.ts')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51752700",
   "metadata": {},
   "source": [
    "## Convert the ONNX model to TensorRT engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87573491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restart the notebook kernel\n",
    "import os\n",
    "os._exit(00)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b829bac6",
   "metadata": {},
   "source": [
    "- Convert to FP32 engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b1100d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!trtexec --onnx=./models/cls.onnx --saveEngine=./models/cls_32.engine "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f059a9f",
   "metadata": {},
   "source": [
    "- Convert to FP16 engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce14e1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!trtexec --onnx=./models/cls.onnx --saveEngine=./models/cls_16.engine --fp16 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba3cdc6",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded08779",
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchmark import NativeTorchBenchmark, TensorRTBehcnmark, TorchScriptBenchmark, TorchTensorRTBenchmark\n",
    "import numpy as np\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "\n",
    "n_infers = 100\n",
    "batch_size = 1\n",
    "\n",
    "input_image = np.random.normal(size=[batch_size, 3, 256, 256])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8828a5f",
   "metadata": {},
   "source": [
    "- Native PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a065626",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
    "\n",
    "pt_bm = NativeTorchBenchmark(n_infers=n_infers,\n",
    "                             batch_size=batch_size,\n",
    "                             samples=input_image,\n",
    "                             model_arch=model,\n",
    "                             model_ckpt='./models/cls.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a14ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_bm.benchmark()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de71b16",
   "metadata": {},
   "source": [
    "- Torch Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e446b897",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
    "\n",
    "ts_bm = TorchScriptBenchmark(n_infers=n_infers,\n",
    "                             batch_size=batch_size,\n",
    "                             samples=input_image,\n",
    "                             model_arch=model,\n",
    "                             model_ckpt='./models/cls.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413b1dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_bm.benchmark()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94f3782",
   "metadata": {},
   "source": [
    "- Torch-TensorRT (FP16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e00dc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_trt_bm = TorchTensorRTBenchmark(n_infers=n_infers,\n",
    "                                   batch_size=batch_size,\n",
    "                                   samples=input_image,\n",
    "                                   model_path='./models/cls_torchtrt.ts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf6d8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_trt_bm.benchmark()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53eb2f5",
   "metadata": {},
   "source": [
    "- TensorRT FP32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7a9b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "trt_bm_fp32 = TensorRTBehcnmark(n_infers=n_infers,\n",
    "                                batch_size=batch_size,\n",
    "                                samples=input_image,\n",
    "                                engine_path='./models/cls_32.engine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112aefbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "trt_bm_fp32.benchmark()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c65de7",
   "metadata": {},
   "source": [
    "- TensorRT FP16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fbc3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trt_bm_fp16 = TensorRTBehcnmark(n_infers=n_infers,\n",
    "                                batch_size=batch_size,\n",
    "                                samples=input_image,\n",
    "                                engine_path='./models/cls_16.engine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66730fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "trt_bm_fp16.benchmark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d829d9bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
